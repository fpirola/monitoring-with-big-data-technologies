# Flume agent configuration.
# Copyright (C) 2015 Fabio Pirola <fabio@pirola.org>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

# Name the components on this agent
syslogAgentStep3.sources = r1
syslogAgentStep3.sinks = s1
syslogAgentStep3.channels = c1

# Describe/configure the source
# I'll be using TCP based Syslog source
syslogAgentStep3.sources.r1.type = syslogtcp
# Host name or IP address to bind to
syslogAgentStep3.sources.r1.host = localhost
# Port # to bind to
syslogAgentStep3.sources.r1.port = 5140

# List of interceptors
syslogAgentStep3.sources.r1.interceptors = attach-schema morphline
# Add the schema for our record sink
syslogAgentStep3.sources.r1.interceptors.attach-schema.type = static
syslogAgentStep3.sources.r1.interceptors.attach-schema.key = flume.avro.schema.url
syslogAgentStep3.sources.r1.interceptors.attach-schema.value = file:/home/cloudera/monitoring-with-big-data-technologies-part-two/step-3/SyslogEvent.avsc
# Morphline interceptor configuration
syslogAgentStep3.sources.r1.interceptors.morphline.type = org.apache.flume.sink.solr.morphline.MorphlineInterceptor$Builder
syslogAgentStep3.sources.r1.interceptors.morphline.morphlineFile = /home/cloudera/monitoring-with-big-data-technologies-part-two/step-3/morphline.conf
syslogAgentStep3.sources.r1.interceptors.morphline.morphlineId = syslogToAvro

# Describe/configure the channel
# Use a channel which buffers events in memory
syslogAgentStep3.channels.c1.type = memory
# The maximum number of events stored in the channel
syslogAgentStep3.channels.c1.capacity = 1000
# The maximum number of events the channel will take from a source
# or give to a sink per transaction
syslogAgentStep3.channels.c1.transactionCapacity = 100

# Describe the sink
# Save to Hadoop HDFS
syslogAgentStep3.sinks.s1.type = hdfs
# HDFS directory path
syslogAgentStep3.sinks.s1.hdfs.path = /monitoring/syslog/%Y-%m-%d
# Name prefixed to files created by Flume in hdfs directory
syslogAgentStep3.sinks.s1.hdfs.filePrefix = syslog_%Y_%m_%d_
# Prefix that is used for temporal files that flume actively writes into
# In order to avoid error on reading temporary data from
# Hive, file actively writes will be prefixed by '_' character.
# Files start with '_' are hidden for hadoop so in this way
# Hive doesn't query these temporary files.
syslogAgentStep3.sinks.s1.hdfs.inUsePrefix = _
# File size to trigger roll, in bytes
syslogAgentStep3.sinks.s1.hdfs.rollSize = 131072
# Timeout after which inactive files get closed
syslogAgentStep3.sinks.s1.hdfs.idleTimeout = 60
# Text file format
syslogAgentStep3.sinks.s1.hdfs.fileType = DataStream
# Number of threads per HDFS sink
syslogAgentStep3.sinks.s1.hdfs.threadsPoolSize = 10
# Store header and text in avro format
syslogAgentStep3.sinks.s1.serializer =org.apache.flume.sink.hdfs.AvroEventSerializer$Builder

# Binding source/channel/sink
syslogAgentStep3.sources.r1.channels = c1
syslogAgentStep3.sinks.s1.channel = c1
